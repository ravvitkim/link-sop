"""
GMP/SOP ì—ì´ì „íŠ¸ ëª¨ë“ˆ v1.0

ğŸ¤– ReAct ì—ì´ì „íŠ¸ + LangSmith ì¶”ì 
- ë„êµ¬: ChromaDB ê²€ìƒ‰, Neo4j ê·¸ë˜í”„ ê²€ìƒ‰
- LLMì´ ìƒí™©ì— ë§ëŠ” ë„êµ¬ë¥¼ ì„ íƒí•´ì„œ ì‹¤í–‰
- LangSmithë¡œ ì‹¤í–‰ ê³¼ì • ëª¨ë‹ˆí„°ë§
"""

import os
from typing import List, Dict, Optional, Any, Annotated, TypedDict
from datetime import datetime

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LangSmith ì„¤ì • (ë§¨ ìœ„ì—ì„œ ì„¤ì •í•´ì•¼ í•¨)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ê±°ë‚˜ ì§ì ‘ ì…ë ¥
LANGSMITH_API_KEY = os.getenv("LANGCHAIN_API_KEY", "")
LANGSMITH_PROJECT = os.getenv("LANGCHAIN_PROJECT", "gmp-sop-agent")

if LANGSMITH_API_KEY:
    os.environ["LANGCHAIN_TRACING_V2"] = "true"
    os.environ["LANGCHAIN_API_KEY"] = LANGSMITH_API_KEY
    os.environ["LANGCHAIN_PROJECT"] = LANGSMITH_PROJECT
    print(f"âœ… LangSmith ì—°ë™ í™œì„±í™”: {LANGSMITH_PROJECT}")
else:
    print("âš ï¸ LangSmith API í‚¤ ì—†ìŒ - ë¡œì»¬ ëª¨ë“œë¡œ ì‹¤í–‰")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì˜ì¡´ì„± ì„í¬íŠ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

try:
    from langchain_core.tools import tool
    from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
    from langchain_core.language_models.chat_models import BaseChatModel
    from langchain_core.outputs import ChatResult, ChatGeneration
    LANGCHAIN_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ LangChain íŒ¨í‚¤ì§€ í•„ìš”: pip install langchain langchain-core")
    LANGCHAIN_AVAILABLE = False

try:
    from langgraph.prebuilt import create_react_agent
    from langgraph.checkpoint.memory import MemorySaver
    LANGGRAPH_AGENT_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ LangGraph ì—ì´ì „íŠ¸ íŒ¨í‚¤ì§€ í•„ìš”: pip install langgraph")
    LANGGRAPH_AGENT_AVAILABLE = False

# Z.AI SDK
try:
    from zai import ZaiClient
    ZAI_AVAILABLE = True
except ImportError:
    ZAI_AVAILABLE = False
    print(f"âš ï¸ Z.AI SDK í•„ìš”: pip install zai-sdk")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë„êµ¬ ì •ì˜ (Tools)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ì „ì—­ ë³€ìˆ˜ (ì´ˆê¸°í™” ì‹œ ì„¤ì •)
_vector_store = None
_graph_store = None


def init_agent_tools(vector_store_module, graph_store_instance):
    """ì—ì´ì „íŠ¸ ë„êµ¬ ì´ˆê¸°í™”"""
    global _vector_store, _graph_store
    _vector_store = vector_store_module
    _graph_store = graph_store_instance
    print("âœ… ì—ì´ì „íŠ¸ ë„êµ¬ ì´ˆê¸°í™” ì™„ë£Œ")


@tool
def search_sop_documents(query: str) -> str:
    """
    SOP ë¬¸ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì˜ë¯¸ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    ì¼ë°˜ì ì¸ ì§ˆë¬¸, ì ˆì°¨ í™•ì¸, ì •ì˜ ê²€ìƒ‰ ë“±ì— ì‚¬ìš©í•˜ì„¸ìš”.
    
    Args:
        query: ê²€ìƒ‰í•  ë‚´ìš© (ì˜ˆ: "í’ˆì§ˆê´€ë¦¬ì±…ì„ìì˜ ì—­í• ", "ë¬¸ì„œ ë³€ê²½ ì ˆì°¨")
    
    Returns:
        ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©ê³¼ ì¶œì²˜
    """
    if not _vector_store:
        return "âŒ ë²¡í„° ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    try:
        results = _vector_store.search(
            query=query,
            collection_name="documents",
            model_name="intfloat/multilingual-e5-small",
            n_results=10,
            similarity_threshold=0.3
        )
        
        if not results:
            return f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        output = []
        for i, r in enumerate(results, 1):
            meta = r.get("metadata", {})
            sop_id = meta.get("sop_id", "N/A")
            section = meta.get("section_path", meta.get("section", ""))
            page = meta.get("page", "")
            similarity = r.get("similarity", 0)
            text = r.get("text", "")[:500]
            
            source = f"[{sop_id}]"
            if section:
                source += f" > {section}"
            if page:
                source += f" (p.{page})"
            
            output.append(f"ğŸ“„ {source} (ìœ ì‚¬ë„: {similarity:.0%})\n{text}...")
        
        return "\n\n---\n\n".join(output)
    
    except Exception as e:
        return f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"


@tool
def get_document_references(sop_id: str) -> str:
    """
    íŠ¹ì • SOP ë¬¸ì„œê°€ ì°¸ì¡°í•˜ëŠ” ë‹¤ë¥¸ ë¬¸ì„œ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    ë¬¸ì„œ ê°„ ê´€ê³„ë‚˜ ì—°ê´€ ê·œì •ì„ ì°¾ì„ ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
    
    Args:
        sop_id: SOP ë¬¸ì„œ ID (ì˜ˆ: "EQ-SOP-00001")
    
    Returns:
        ì°¸ì¡°í•˜ëŠ” ë¬¸ì„œ ëª©ë¡ê³¼ ì°¸ì¡°ë°›ëŠ” ë¬¸ì„œ ëª©ë¡
    """
    if not _graph_store:
        return "âŒ ê·¸ë˜í”„ ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    try:
        # sop_id ì •ê·œí™”
        sop_id = sop_id.upper().strip()
        if not sop_id.startswith("EQ-"):
            sop_id = "EQ-" + sop_id
        
        refs = _graph_store.get_document_references(sop_id)
        
        if not refs:
            return f"'{sop_id}' ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ì°¸ì¡° ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        doc = refs.get("document", {})
        references = refs.get("references", [])
        cited_by = refs.get("cited_by", [])
        
        output = [f"ğŸ“„ ë¬¸ì„œ: {doc.get('sop_id', sop_id)} - {doc.get('title', '')}"]
        
        if references:
            output.append(f"\nğŸ”— ì°¸ì¡°í•˜ëŠ” ë¬¸ì„œ ({len(references)}ê°œ):")
            for ref in references:
                output.append(f"  â†’ {ref}")
        else:
            output.append("\nğŸ”— ì°¸ì¡°í•˜ëŠ” ë¬¸ì„œ: ì—†ìŒ")
        
        if cited_by:
            output.append(f"\nğŸ“¥ ì°¸ì¡°ë°›ëŠ” ë¬¸ì„œ ({len(cited_by)}ê°œ):")
            for ref in cited_by:
                output.append(f"  â† {ref}")
        else:
            output.append("\nğŸ“¥ ì°¸ì¡°ë°›ëŠ” ë¬¸ì„œ: ì—†ìŒ")
        
        return "\n".join(output)
    
    except Exception as e:
        return f"âŒ ì°¸ì¡° ì¡°íšŒ ì˜¤ë¥˜: {str(e)}"


@tool
def search_sections_by_keyword(keyword: str, sop_id: str = None) -> str:
    """
    í‚¤ì›Œë“œë¡œ ë¬¸ì„œ ì„¹ì…˜ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    íŠ¹ì • ìš©ì–´ë‚˜ ê°œë…ì´ ì–´ëŠ ì„¹ì…˜ì— ì •ì˜ë˜ì–´ ìˆëŠ”ì§€ ì°¾ì„ ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
    
    Args:
        keyword: ê²€ìƒ‰í•  í‚¤ì›Œë“œ (ì˜ˆ: "ì±…ì„", "ì ˆì°¨", "ê¸°ë¡")
        sop_id: íŠ¹ì • ë¬¸ì„œë¡œ í•œì •í•  ê²½ìš° SOP ID (ì„ íƒì‚¬í•­)
    
    Returns:
        í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì„¹ì…˜ ëª©ë¡
    """
    if not _graph_store:
        return "âŒ ê·¸ë˜í”„ ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    try:
        results = _graph_store.search_sections(keyword, sop_id=sop_id, limit=5)
        
        if not results:
            scope = f" ({sop_id} ë‚´)" if sop_id else ""
            return f"'{keyword}' í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤{scope}."
        
        output = [f"ğŸ” '{keyword}' ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê°œ):"]
        
        for sec in results:
            sop = sec.get("doc_sop_id", "N/A")
            name = sec.get("name", "")
            path = sec.get("section_path", "")
            page = sec.get("page", "")
            
            location = f"[{sop}] {name}"
            if path:
                location += f"\n   ğŸ“ {path}"
            if page:
                location += f" (p.{page})"
            
            output.append(f"\nğŸ“„ {location}")
        
        return "\n".join(output)
    
    except Exception as e:
        return f"âŒ ì„¹ì…˜ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"


@tool
def get_document_structure(sop_id: str) -> str:
    """
    íŠ¹ì • SOP ë¬¸ì„œì˜ ì„¹ì…˜ ê³„ì¸µ êµ¬ì¡°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    ë¬¸ì„œì˜ ëª©ì°¨ë‚˜ êµ¬ì„±ì„ íŒŒì•…í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
    
    Args:
        sop_id: SOP ë¬¸ì„œ ID (ì˜ˆ: "EQ-SOP-00001")
    
    Returns:
        ë¬¸ì„œì˜ ì„¹ì…˜ ê³„ì¸µ êµ¬ì¡°
    """
    if not _graph_store:
        return "âŒ ê·¸ë˜í”„ ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    try:
        sop_id = sop_id.upper().strip()
        if not sop_id.startswith("EQ-"):
            sop_id = "EQ-" + sop_id
        
        hierarchy = _graph_store.get_section_hierarchy(sop_id)
        
        if not hierarchy:
            return f"'{sop_id}' ë¬¸ì„œì˜ êµ¬ì¡°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        output = [f"ğŸ“‹ {sop_id} ë¬¸ì„œ êµ¬ì¡°:"]
        
        for item in hierarchy[:15]:  # ìƒìœ„ 15ê°œë§Œ
            sec = item.get("section", {})
            name = sec.get("name", "")
            sec_type = sec.get("section_type", "")
            children = item.get("children", [])
            
            # ë“¤ì—¬ì“°ê¸°
            indent = ""
            if sec_type == "subsection":
                indent = "  "
            elif sec_type == "subsubsection":
                indent = "    "
            
            child_info = f" ({len(children)}ê°œ í•˜ìœ„)" if children else ""
            output.append(f"{indent}â€¢ {name}{child_info}")
        
        if len(hierarchy) > 15:
            output.append(f"  ... ì™¸ {len(hierarchy) - 15}ê°œ ì„¹ì…˜")
        
        return "\n".join(output)
    
    except Exception as e:
        return f"âŒ êµ¬ì¡° ì¡°íšŒ ì˜¤ë¥˜: {str(e)}"


@tool
def list_all_documents() -> str:
    """
    ì‹œìŠ¤í…œì— ë“±ë¡ëœ ëª¨ë“  SOP ë¬¸ì„œ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    ì–´ë–¤ ë¬¸ì„œê°€ ìˆëŠ”ì§€ íŒŒì•…í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
    
    Returns:
        ë“±ë¡ëœ SOP ë¬¸ì„œ ëª©ë¡
    """
    if not _graph_store:
        return "âŒ ê·¸ë˜í”„ ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    try:
        docs = _graph_store.get_all_documents()
        
        if not docs:
            return "ë“±ë¡ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."
        
        output = [f"ğŸ“š ë“±ë¡ëœ SOP ë¬¸ì„œ ({len(docs)}ê°œ):"]
        
        for doc in docs:
            sop_id = doc.get("sop_id", "N/A")
            title = doc.get("title", "")
            sections = doc.get("section_count", 0)
            output.append(f"  â€¢ {sop_id}: {title} ({sections}ê°œ ì„¹ì…˜)")
        
        return "\n".join(output)
    
    except Exception as e:
        return f"âŒ ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì—ì´ì „íŠ¸ ìƒì„±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ë„êµ¬ ë¦¬ìŠ¤íŠ¸
AGENT_TOOLS = [
    search_sop_documents,
    get_document_references,
    search_sections_by_keyword,
    get_document_structure,
    list_all_documents,
]


# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
AGENT_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ GMP(ì˜ì•½í’ˆ ì œì¡° ë° í’ˆì§ˆê´€ë¦¬) ê·œì • ì „ë¬¸ê°€ AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.

## ì—­í• 
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ SOP(í‘œì¤€ì‘ì—…ì ˆì°¨ì„œ) ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.

## ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬
1. **search_sop_documents**: SOP ë¬¸ì„œ ë‚´ìš© ê²€ìƒ‰ (ì˜ë¯¸ ê¸°ë°˜)
2. **get_document_references**: ë¬¸ì„œ ê°„ ì°¸ì¡° ê´€ê³„ ì¡°íšŒ
3. **search_sections_by_keyword**: í‚¤ì›Œë“œë¡œ ì„¹ì…˜ ê²€ìƒ‰
4. **get_document_structure**: ë¬¸ì„œ ëª©ì°¨/êµ¬ì¡° ì¡°íšŒ
5. **list_all_documents**: ì „ì²´ ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ

## ë‹µë³€ ì›ì¹™
1. ë°˜ë“œì‹œ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ê²€ìƒ‰í•œ í›„ ë‹µë³€í•˜ì„¸ìš”.
2. ì¶œì²˜(SOP ID, ì„¹ì…˜)ë¥¼ ëª…í™•íˆ ë°íˆì„¸ìš”.
3. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì†”ì§íˆ ë§í•˜ì„¸ìš”.
4. ì¶”ì¸¡í•˜ì§€ ë§ê³  ë¬¸ì„œ ë‚´ìš©ë§Œ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

## ë„êµ¬ ì„ íƒ ê°€ì´ë“œ
- ì¼ë°˜ì ì¸ ì§ˆë¬¸ â†’ search_sop_documents
- "ì°¸ì¡°í•˜ëŠ” ë¬¸ì„œ", "ê´€ë ¨ ê·œì •" â†’ get_document_references
- íŠ¹ì • ìš©ì–´/í‚¤ì›Œë“œ ìœ„ì¹˜ â†’ search_sections_by_keyword
- ë¬¸ì„œ êµ¬ì„±/ëª©ì°¨ â†’ get_document_structure
- ì–´ë–¤ ë¬¸ì„œê°€ ìˆëŠ”ì§€ â†’ list_all_documents
"""


class AgentState(TypedDict):
    """ì—ì´ì „íŠ¸ ìƒíƒœ"""
    messages: List[Any]
    

# ë©”ëª¨ë¦¬ (ëŒ€í™” íˆìŠ¤í† ë¦¬ ìœ ì§€)
_memory_saver = None
_agent = None


def create_agent(model_name: str = "glm-4.7-flash"):
    """ì—ì´ì „íŠ¸ ìƒì„± (Z.AI ê¸°ë°˜)"""
    global _agent, _memory_saver
    
    if not ZAI_AVAILABLE:
        raise ImportError("Z.AI SDKê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install zai-sdk")
    
    # Z.AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    api_key = os.getenv("ZAI_API_KEY", "")
    if not api_key:
        raise ValueError("ZAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    _agent = {
        "model": model_name,
        "api_key": api_key,
        "client": ZaiClient(api_key=api_key)
    }
    
    _memory_saver = MemorySaver() if LANGGRAPH_AGENT_AVAILABLE else {}
    
    print(f"âœ… Z.AI ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ: {model_name}")
    return _agent


def run_agent(
    query: str,
    session_id: str = "default",
    model_name: str = "glm-4.7-flash"
) -> Dict[str, Any]:
    """
    Z.AI ì—ì´ì „íŠ¸ ì‹¤í–‰ (ReAct ìŠ¤íƒ€ì¼)
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        session_id: ì„¸ì…˜ ID
        model_name: Z.AI ëª¨ë¸ëª…
    
    Returns:
        {
            "answer": "ë‹µë³€ í…ìŠ¤íŠ¸",
            "tool_calls": [...],
            "session_id": "ì„¸ì…˜ID"
        }
    """
    global _agent
    
    # ì—ì´ì „íŠ¸ê°€ ì—†ìœ¼ë©´ ìƒì„±
    if _agent is None:
        create_agent(model_name)
    
    client = _agent["client"]
    tool_calls = []
    context_parts = []
    
    print(f"ğŸ”„ Z.AI ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘... ({model_name})")
    
    try:
        # 1. ë¨¼ì € LLMì—ê²Œ ë„êµ¬ ì„ íƒì„ ìš”ì²­
        tool_selection_prompt = f"""{AGENT_SYSTEM_PROMPT}

ì‚¬ìš©ì ì§ˆë¬¸: {query}

ìœ„ ì§ˆë¬¸ì— ë‹µí•˜ë ¤ë©´ ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.
ë„êµ¬ ì´ë¦„ë§Œ ì§§ê²Œ ì‘ë‹µí•˜ì„¸ìš”:
- search_sop_documents: ì¼ë°˜ì ì¸ ë‚´ìš© ê²€ìƒ‰
- get_document_references: ë¬¸ì„œ ê°„ ì°¸ì¡° ê´€ê³„
- search_sections_by_keyword: í‚¤ì›Œë“œë¡œ ì„¹ì…˜ ê²€ìƒ‰
- get_document_structure: ë¬¸ì„œ ëª©ì°¨/êµ¬ì¡°
- list_all_documents: ì „ì²´ ë¬¸ì„œ ëª©ë¡

ì‘ë‹µ í˜•ì‹: [ë„êµ¬ì´ë¦„]
ì˜ˆ: search_sop_documents"""

        tool_response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": tool_selection_prompt}],
            max_tokens=100,
            temperature=0.1,
        )
        
        tool_msg = tool_response.choices[0].message
        selected_tool = getattr(tool_msg, 'content', "") or ""
        
        # 'ìƒê°' ëª¨ë“œë¡œ ì¸í•´ contentê°€ ë¹„ì–´ìˆì„ ê²½ìš° ëŒ€ì‘
        if not selected_tool:
            reasoning = getattr(tool_msg, 'reasoning_content', "").lower()
            selected_tool = "search_sop_documents" if "search" in reasoning or "ê²€ìƒ‰" in reasoning else "search_sop_documents"
        
        selected_tool = selected_tool.strip().lower()
        print(f"ğŸ”§ ì„ íƒëœ ë„êµ¬: {selected_tool}")
        
        # 2. ë„êµ¬ ì‹¤í–‰
        tool_result = ""
        
        if "search_sop_documents" in selected_tool or "ê²€ìƒ‰" in selected_tool:
            tool_result = search_sop_documents.invoke(query)
            tool_calls.append({"tool": "search_sop_documents", "input": query, "output": tool_result[:300]})
            
        elif "references" in selected_tool or "ì°¸ì¡°" in selected_tool:
            import re
            sop_match = re.search(r'(EQ-?SOP-?\d+)', query, re.IGNORECASE)
            if sop_match:
                sop_id = sop_match.group(1).upper()
                tool_result = get_document_references.invoke(sop_id)
                tool_calls.append({"tool": "get_document_references", "input": sop_id, "output": tool_result[:300]})
            else:
                tool_result = search_sop_documents.invoke(query)
                tool_calls.append({"tool": "search_sop_documents", "input": query, "output": tool_result[:300]})
                
        elif "keyword" in selected_tool or "í‚¤ì›Œë“œ" in selected_tool:
            # ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = query.replace("?", "").replace("ì€", "").replace("ëŠ”", "").split()[-1]
            tool_result = search_sections_by_keyword.invoke(keywords)
            tool_calls.append({"tool": "search_sections_by_keyword", "input": keywords, "output": tool_result[:300]})
            
        elif "structure" in selected_tool or "êµ¬ì¡°" in selected_tool or "ëª©ì°¨" in selected_tool:
            import re
            sop_match = re.search(r'(EQ-?SOP-?\d+)', query, re.IGNORECASE)
            if sop_match:
                sop_id = sop_match.group(1).upper()
                tool_result = get_document_structure.invoke(sop_id)
                tool_calls.append({"tool": "get_document_structure", "input": sop_id, "output": tool_result[:300]})
            else:
                tool_result = list_all_documents.invoke({})
                tool_calls.append({"tool": "list_all_documents", "input": "", "output": tool_result[:300]})
                
        elif "list" in selected_tool or "ëª©ë¡" in selected_tool:
            tool_result = list_all_documents.invoke({})
            tool_calls.append({"tool": "list_all_documents", "input": "", "output": tool_result[:300]})
            
        else:
            # ê¸°ë³¸: ê²€ìƒ‰
            tool_result = search_sop_documents.invoke(query)
            tool_calls.append({"tool": "search_sop_documents", "input": query, "output": tool_result[:300]})
        
        print(f"ğŸ“„ ë„êµ¬ ê²°ê³¼ ê¸¸ì´: {len(tool_result)} ê¸€ì")
        
        # 3. ìµœì¢… ë‹µë³€ ìƒì„±
        final_prompt = f"""{AGENT_SYSTEM_PROMPT}

[ê²€ìƒ‰ ê²°ê³¼]
{tool_result}

[ì‚¬ìš©ì ì§ˆë¬¸]
{query}

ìœ„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µë³€í•˜ì„¸ìš”.
ë°˜ë“œì‹œ ì¶œì²˜(SOP ID, ì„¹ì…˜)ë¥¼ ëª…ì‹œí•˜ì„¸ìš”."""

        final_response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": final_prompt}],
            max_tokens=2048,  # í† í° ìƒí–¥
            temperature=0.7,
        )
        
        msg_obj = final_response.choices[0].message
        answer = getattr(msg_obj, 'content', "") or ""
        reasoning = getattr(msg_obj, 'reasoning_content', "") or ""
        
        if not answer and reasoning:
            answer = f"[ë¶„ì„ ë‚´ìš©]\n{reasoning}\n\nâš ï¸ ë‹µë³€ ìƒì„± ì¤‘ í† í° ì œí•œìœ¼ë¡œ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤."
            
        print(f"âœ… ìµœì¢… ë‹µë³€ ê¸¸ì´: {len(answer)} ê¸€ì")
        
        return {
            "answer": answer,
            "tool_calls": tool_calls,
            "session_id": session_id,
            "success": True
        }
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {
            "answer": f"Z.AI ì—ì´ì „íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}",
            "tool_calls": [],
            "session_id": session_id,
            "success": False
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ê°„ë‹¨í•œ í´ë°± ì—ì´ì „íŠ¸ (LangGraph ì—†ì´)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_simple_agent(
    query: str,
    vector_store_module,
    graph_store_instance,
    llm_model: str = "qwen2.5:3b"
) -> Dict[str, Any]:
    """
    ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ì—ì´ì „íŠ¸ (LangGraph ì—†ì´ ë™ì‘)
    
    í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ë„êµ¬ ì„ íƒ
    """
    from rag.llm import get_llm_response
    
    tool_calls = []
    context_parts = []
    
    query_lower = query.lower()
    
    # 1. ë¬¸ì„œ ëª©ë¡ ì§ˆë¬¸
    if any(kw in query_lower for kw in ["ë¬¸ì„œ ëª©ë¡", "ì–´ë–¤ ë¬¸ì„œ", "ë“±ë¡ëœ ë¬¸ì„œ", "sop ëª©ë¡"]):
        try:
            docs = graph_store_instance.get_all_documents()
            result = "\n".join([f"â€¢ {d['sop_id']}: {d.get('title', '')}" for d in docs])
            context_parts.append(f"ğŸ“š ë“±ë¡ëœ ë¬¸ì„œ:\n{result}")
            tool_calls.append({"tool": "list_all_documents", "result": result[:200]})
        except Exception as e:
            context_parts.append(f"ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    # 2. ì°¸ì¡° ê´€ê³„ ì§ˆë¬¸
    elif any(kw in query_lower for kw in ["ì°¸ì¡°", "ê´€ë ¨ ë¬¸ì„œ", "ì—°ê´€", "ê´€ê³„"]):
        import re
        sop_match = re.search(r'(EQ-?SOP-?\d+)', query, re.IGNORECASE)
        if sop_match:
            sop_id = sop_match.group(1).upper().replace("SOP", "-SOP-").replace("--", "-")
            try:
                refs = graph_store_instance.get_document_references(sop_id)
                if refs:
                    context_parts.append(f"ğŸ“„ {sop_id} ì°¸ì¡° ê´€ê³„:\n- ì°¸ì¡°: {refs.get('references', [])}\n- í”¼ì°¸ì¡°: {refs.get('cited_by', [])}")
                    tool_calls.append({"tool": "get_document_references", "input": sop_id})
            except:
                pass
    
    # 3. ë¬¸ì„œ êµ¬ì¡° ì§ˆë¬¸
    elif any(kw in query_lower for kw in ["ëª©ì°¨", "êµ¬ì¡°", "êµ¬ì„±", "ì„¹ì…˜"]):
        import re
        sop_match = re.search(r'(EQ-?SOP-?\d+)', query, re.IGNORECASE)
        if sop_match:
            sop_id = sop_match.group(1).upper().replace("SOP", "-SOP-").replace("--", "-")
            try:
                hierarchy = graph_store_instance.get_section_hierarchy(sop_id)
                if hierarchy:
                    sections = [h['section']['name'] for h in hierarchy[:10]]
                    context_parts.append(f"ğŸ“‹ {sop_id} êµ¬ì¡°:\n" + "\n".join([f"â€¢ {s}" for s in sections]))
                    tool_calls.append({"tool": "get_document_structure", "input": sop_id})
            except:
                pass
    
    # 4. ê¸°ë³¸: ë²¡í„° ê²€ìƒ‰
    if not context_parts:
        try:
            results = vector_store_module.search(
                query=query,
                collection_name="documents",
                model_name="intfloat/multilingual-e5-small",
                n_results=3
            )
            for r in results:
                meta = r.get("metadata", {})
                sop = meta.get("sop_id", "")
                path = meta.get("section_path", "")
                text = r.get("text", "")[:400]
                context_parts.append(f"[{sop}] {path}\n{text}")
            tool_calls.append({"tool": "search_sop_documents", "input": query})
        except Exception as e:
            context_parts.append(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
    
    # LLM ë‹µë³€ ìƒì„±
    context = "\n\n---\n\n".join(context_parts)
    
    prompt = f"""ë‹¹ì‹ ì€ GMP/SOP ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

[ê²€ìƒ‰ ê²°ê³¼]
{context}

[ì§ˆë¬¸]
{query}

[ë‹µë³€] (ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”):"""
    
    answer = get_llm_response(prompt, llm_model=llm_model, max_tokens=512)
    
    return {
        "answer": answer,
        "tool_calls": tool_calls,
        "context": context[:500],
        "success": True
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# í…ŒìŠ¤íŠ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸ¤– GMP/SOP ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    # í…ŒìŠ¤íŠ¸ (ë„êµ¬ ì´ˆê¸°í™” ì—†ì´ êµ¬ì¡°ë§Œ í™•ì¸)
    print("\nğŸ“‹ ë“±ë¡ëœ ë„êµ¬:")
    for tool in AGENT_TOOLS:
        print(f"  â€¢ {tool.name}: {tool.description[:50]}...")
    
    print("\nâœ… ì—ì´ì „íŠ¸ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ!")
    print("   ì‚¬ìš©ë²•: from agent import run_agent, init_agent_tools")